## 유튜브 개발바닥에서 물어보는 질문들이란? [Link](https://www.youtube.com/watch?v=3ArYMq5AomI&t=6s)

### ◆ HttpSession으로 개발했을 때, Key 값이 같다면 어떻게 분리하는가?
보통 DB 같은 경우 Query Parameter가 계속 바뀌어 전송되어 다른 값을 구분해서 가져오지만 Session은 이미 같은 Key 값으로 고정되어 있는 상태에서 사용자에 따라 구분한다.   

스프링을 공부하면서 <b>HttpSession</b>으로 개발을 경험해보았지만 <b>Key값이 같을 때</b>, 분리하여 사용하는 방법을 생각해 본 적이 없었다. 그래서 한 번 검색해 보았다.   

모든 BackEnd 언어의 Session의 <b>동작 방식이 동일</b>하다고 한다. 이는 스프링의 HttpSession을 비롯하여 모든 BackEnd 언어의 동작 방식이 같다는 것이다.   

서버에서 Session을 사용을 설정할 경우에는 클라이언트가 해당 서버에 접속했을 때, 서버에는 Session 파일을 하나 생성한다. 그리고 서버는 브라우저에 JSESSIONID라는 <b>쿠키</b>를 전송한다. (쿠키명 변경 가능)   

이제 브라우저는 다른 페이지로 이동할 때마다 JSESSIONID를 서버로 <b>함께 전송</b>한다. 그러면 서버는 JSESSIONID 쿠키 값을 보고 A 브라우저는 A Session이 매칭되었다는 것을 인지하고 <b>사용자를 확인</b>할 수 있다.   

브라우저마다 Session 값이 겹치지 않는 이유는 브라우저 별로 별도의 쿠키를 관리하고 쿠키를 별도로 관리하기 때문에 서버에서는 같은 사용자로 인식하지 못한다. 예를 들어 로그인 기능을 만들 때, 다른 브라우저에서 같은 아이디로 접속하더라도 쿠키명이 달라지게 된다.   

국내에서는 이렇게 쿠키를 사용하여 인증 방식을 채택하였지만, 보안 문제가 발생하였다. 그래서 Session을 이용해서 중요한 데이터는 서버가 관리하고, 해당 Session의 ID (기본키)를 클라이언트의 브라우저에 전달하여 인증을 구현한다.   

위의 내용은 <b>Servlet</b>에서 지원한다.   
서버는 HttpServletRequest에서 getSession을 통해 HttpSession을 가져다 사용하면 되며 클라이언트에는 브라우저가 서버의 자원을 요청할 시, 항상 쿠키를 Header에 함께 포함시키기 때문에 별도의 작업은 필요하지 않으나 Cookie 사용 안함 시 Session은 유지되지 않는다.   

---

### ◆ Shell Script로 배포 스크립트를 만들었을 때, 다른 언어와의 return의 차이점은?   
-

---

### ◆ JPA N + 1이 발생했을 때, 원인과 해결 방법이 무엇이며 Join 쿼리를 이용하면 어떻게 되는가?
JPQL을 실행하면 JPA는 이를 분석하여 SQL를 생성한다. JPQL 입장에서는 즉시 로딩, 자연 로딩과 같은 글로벌 패치 전략을 무시하고 JPQL만 사용해서 SQL을 생성한다.   

JPQL은 특징이 있다. findById()같은 경우에는 엔티티를 영속성 컨텍스트에서 먼저 찾고 영속성 컨텍스트에 없는 경우 DB에서 찾지만 JPQL은 항상 DB에 SQL을 실행해서 결과를 조회한다. 그리고 다음과 같은 작업을 진행한다.   
1. JPQL을 호출하면 DB에 우선적으로 조회   
2. 조회한 값을 영속성 컨텍스트에 저장   
3. 영속성 컨텍스트에 조회할 때 이미 존재하는 데이터가 있다면 데이터를 버림   

JPA N + 1이 발생하는 이유는 JPQL에서 글로벌 패치 전략을 완전히 무시하고 SQL을 생선한다.   

findAll()의 경우 아래처럼 호출한다.
```
SELECT * FROM MEMBER
```
즉시 로딩인 경우
```
val members = memberRepository.findAll()
```
JPQL에서 동작한 쿼리를 통해 members에 데이터가 바인딩된다. 그 이후 JPA에서는 글로벌 패치 전략(즉시 로딩)을 받아 들여 해당 member에 대해 추가적인 LAZY 로딩으로 N + 1을 발생시킨다.   

지연 로딩인 경우
```
val members = memberRepository.findAll()
```
동일하게 members에 데이터가 바인딩되지만 JPA가 글로벌 패치 전략을 받아들이지만 지연 로딩이기 때문에 추가적인 SQL을 발생시키지 않는다. 하지만 LAZY 로딩으로 추가 작업을 진행하면 N + 1 문제가 발생한다.   

#### 해결 방법
1. Batch Size   
@BatchSize(size = 크기)를 지정한다. size 만큼 데이터를 미리 로딩하며 연관된 엔티티를 조회할 때 size만큼 WHERE IN 쿼리를 통해 조회하게 되고 size를 넘어가게 되면 WHERE IN 쿼리를 진행한다. 그러나 글로벌 패치 전략을 변경해야 하며, 정해진 Batch Size만큼 조회되는 것도 고정되기 때문에 권장하지 않는다.   

2. Fetch Join   
쿼리 조회를 위한 Interface를 생성한 후
```
interface MemberRepository : JpaRepository<Member, Long> {
    @Query(
            "select m from Member m left join fetch m.orders"
    )
    
    fun findAllWithFetch(): List<Member>
}

혹은

@Repository
public interface PostRepository extends JpaRepository<Post, Long> {
    @Query("select p from Post p left join fetch p.commentList")
    List<Post> findAllWithFetchJoin(); 
    // findAllWithFetchJoin을 사용함으로써 N + 1 문제를 발생하지 않게 만들 수 있다.
}
```
Fetch Join을 사용한다.
```
@Test
    internal fun `페치 조인 사용`() {
        val members = memberRepository.findAllWithFetch()
        // 조회한 모든 회원에 대해서 조회하는 경우에도 N+1 문제가 발생하지 않음
        for (member in members) {
            println("order size: ${member.orders.size}")
        }
    }
```
가장 많이 사용하는 방법으로 Fetch를 통해 Join 쿼리를 진행한다. Fetch 키워드를 사용하면 연관된 엔티티나 컬렉션을 한 번에 동시 조회할 수 있다. 즉, Fetch Join을 사용하게 되면 연관된 엔티티는 프록시가 아닌 실제 엔티티를 조회하게 되므로 연관 관계 객체까지 한 번의 쿼리로 가져올 수 있다.   

#### 일반 Join의 경우
```
interface MemberRepository : JpaRepository<Member, Long> {
    @Query(
        "select m from Member m join m.orders" // fetch를 제거
    )
    
    fun findAllWithFetch(): List<Member>
}

@Test
internal fun `페치 조인 키워드 제거`() {
    val members = memberRepository.findAllWithFetch() // 패치 타입 Lazy 경우
    // 패치 조인하지 않은 상태에서는 N+1 문제 발생
    for (member in members) {
        println("order size: ${member.orders.size}")
    }
}
```
조인을 통해 연관 관계 컬렉션까지 함께 조회되는 것처럼 보이지만 JPQL은 결과를 반환할 때, 연관 관계까지 고려하지 않고 SELECT 절에 지정한 엔티티만 조회한다. 따라서 컬렉션은 초기화하지 않은 컬렉션 레퍼를 반환하게 되고 컬렉션이 없기 때문에 LAZY 로딩이 발생하게 되고 결과적으로 N + 1 문제가 발생한다.   

#### Fetch Join의 한계
1. 컬렉션을 Fetch Join을 하면 페이징 API를 사용할 수 없다. (메모리 문제)
2. 둘 이상 컬렉션을 Fetch할 수 없다.

---

### ◆ 단방향과 양방향 바인딩의 차이점
#### 데이터 바인딩   
데이터 바인딩이란 <b>두 데이터 혹은 정보의 소스를 모두 일치시키는 기법</b>이다. 즉, 화면에 보이는 데이터와 브라우저 메모리에 있는 데이터를 일치시키는 기법이다.   

자바스크립트 웹 애플리케이션의 복잡도가 증가하면서 브라우저의 메모리에 있는 여러 자바스크립트 객체와 화면에 있는 데이터를 일치시키기 어려워졌다.   

이러한 문제를 해결해주는 것이 데이터 바인딩이다.   
대다수의 자바스크립트 프레임워크는 단방향 데이터 바인딩을 지원하지면 Angular JS는 양방향 데이터 바인딩을 지원한다.   

단방향 데이터 바인딩과 양방향 데이터 바인딩의 차이는 ```HTML에서 변경된 내용이 데이터에 영향을 미치는가?```를 알면 된다.

#### 단방향 데이터 바인딩
단방향 데이터 바인딩은 데이터와 템플릿을 결합하여 화면을 생성한다. Mustache를 이용해 데이터를 바인딩할 경우, 기본적으로 단방향 데이터 바인딩이 이루어진다. 단방향 데이터 바인딩으로 구현할 경우, 사용자 입력에 따라 데이터를 갱신하고 화면을 업데이트해야 하므로 데이터 변화를 감지하고 화면을 업데이트하는 코드를 매번 작성해야 한다.

#### 양방향 데이터 바인딩
양방향 데이터 바인딩은 데이터의 변화를 감지하여 템플릿과 결합해 화면을 갱신하고 화면에서의 입력에 따라 데이터를 갱신한다. 즉, 데이터와 화면 사이의 데이터가 꾸준히 일치하게 되는 것이다.

#### 각 데이터 바인딩 쉽게 이해하기
사용자의 Input을 받는 웹 페이지 경우, 사용자의 입력값이 바로 데이터 상으로 적용되지 않는다. 가능은 하지만 별도의 이벤트를 걸어 다시 이벤트를 통해 화면에 뿌려주어야 한다. 처음 웹 페이지가 렌더링이 되고 데이터를 표시하는 과정이 단방향으로 진행되기 때문에 이후 사용자가 입력한 값을 이벤트 발생 없이 바로 데이터에 적용할 수 없다.   

이렇게 단방향인 경우, 적절한 이벤트를 통해서만 코드 상 변수에 데이터를 담을 수 있지만 양방향인 경우, 사용자의 입력값이 곧바로 코드 상의 변수에 바인딩이 될 수 있다.   

예를 들어서 Vue.js에 경우 HTML에서 v-model을 사용하면 양방향이 가능하다.
```
<input type = "text" v-model = "text">
```

---

### ◆ 로그인 페이지 구현
아이디와 비밀번호를 서버에서 확인해서 Session과 Cookie를 전송
HTTP Header, JSON Body

---

### ◆ 네트워크 예외 처리
* 예외 : 프로그램에 문제가 있는 상태   
* 예외 처리: 예외로 인해 시스템 동작이 멈추는 것을 막는 행위   

#### Status Code
프론트엔드 개발을 하다보면 HTTP 상태 코드를 잘못 사용하거나 다른 오류를 접할 수 있다. 예를 등러서 바로 요청이 실패했을 때, 상태 코드를 요청 성공을 의미하는 <b>200 OK</b>로 내려주는 것이다.
```
GET /api/users/123

HTTP/1.1 200 OK
{ "success": false }
```
위 처럼 HTTP 응답 바디에 요청의 성공 실패 여부 혹은 실패 이유를 담아 담아 보내주는 경우가 대부분이지만 프론트엔드 애플리케이션에서는 처리가 애매한 상황이 발생한다.   

프론트엔드에서는 이런 비동기 요청을 Promise를 통해서 처리하는데, 여기서 문제는 대부분의 HTTP 라이브러리 혹은 API들은 백엔드에서 보내주는 요청의 상태 코드에 따라 요청의 성공과 실패 여부를 판단하고 실패했을 경우에만 에러를 던져 준다.   

그래서 프론트엔드에서는 아래처럼 통신을 담당하는 코드를 작성한다.
```
async function fetchUsers () {
  try {
    const response = await fetch('/api/users/123');
    return response.json();
  }
  catch (e) {
    alert('요청 실패');
  }
}
```
서버로 보낸 요청이 실패했다면 서버는 <b>400</b>, <b>500</b>번대의 상태 코드를 보내주고, 그렇게 되면 <b>fetch</b> API는 에러를 발생시킨다. 그래서 <b>fetch</b>를 사용할 때는 단순하게 외부에서 <b>try / catch</b> 문을 사용하여 간단하게 통신에 대한 에러를 핸들링할 수 있다.   

다만, 백엔드에서 요청이 실패했음에도 상태 코드로 <b>200</b>번대의 코드를 보낸다면 프론트엔드에서는 아래처럼 코드를 작성해야 하는 상황이 온다.
```
async function fetchUsers () {
  try {
    const response = await fetch('/api/users/123');
    const { success } = await response.json();
    if (!success) {
      throw new Error();
    }
  } catch (e) {
    alert('요청 실패');
  }
}
```
if (!success)를 따로 생성하여 에러를 처리하게 된다. 즉, 불필요한 예외 처리가 한 번 더 발생하며, 가독성을 해치지만 어쩔 수 없는 선택을 하게 된다.   

그리고 백엔드에서 미처 핸들링하지 못한 에러나 서버가 죽을 경우, <b>500</b>, <b>502</b>번의 상태 코드가 내려와 <b>try / catch</b> 문을 사용하지 않을 수 있다.

#### HTTP 상태 코드 종류
<b>200</b>번 대는 성공, <b>400</b>번 대는 클라이언트의 요청 에러, <b>500</b>번 대는 서버의 에러이다. 이 처럼 각 상황에 맞는 코드가 표준으로 정해져 있다.   

* <b>100번 대</b>   
프로토콜을 교체 가능하거나 계속 요청을 보내도 가능한 의미
* <b>200번 대 </b>  
클라이언트가 요청한 작업을 서버가 성공적으로 수행했다는 상태의 의미
    * 200 OK: 단순하게 작업이 성공함을 의미
    * 201 Created: 요청이 정상적으로 수행되었으며 리소스가 새롭게 생성되었다는 상태의 의미
    * 204 No Content: 요청이 정상적으로 수행되었으며 관련된 컨텐츠가 더 이상 깔금하게 존재하지 않음을 의미
* <b>300번 대</b> 
Redirect에 관련된 상태들을 의미이며 어떠한 이유로 정상적인 방법으로 더 이상 해당 리소스에 접근할 수 없고 URL로 접근 가능해야 할 때, 서버가 정보를 알려주는 상태
    * 301 Moved Permanetly: 301 Redirect로써 Redirect을 위한 코드 중 가장 많이 사용되는 것. 브라우저는 요청의 응답을 받으면 HTTP 헤더에 있는 Location 필드를 찾고, 존재할 경우 Location 필드에 담긴 URL로 자동으로 Redirect
    * 304 Not Modified: 클라이언트가 요청한 리소스가 이전 요청 때와 비교했을 때, 달라지지 않은 상태
* <b>400번 대</b> 
클라이언트가 서버에 보낸 요청이 잘못된 경우를 의미
    * 400 Bad Request: 클라이언트가 요청을 잘못한 것
    * 401 Unauthorized: 인증되지 않은 사용자가 인증이 필요한 리소스를 요청하는 경우 이를 알려주는 상태 코드
    * 403 Forbidden: 클라이언트가 접근이 금지된 리소스를 요청했음을 의미. 즉, 인증되지 않았다는 것
    * 404 Not Found: 요청한 리소스가 존재하지 않음을 의미
    * 405 Method Not Allowed: 현재 리소스에 맞지 않는 메소드를 사용했음을 의미
    * 406 No Acceptable: 서버 주도 컨텐츠 협상을 진행했음에도 알맞는 컨텐츠 타입이 없음을 의미
    * 408 Request Timeout: 클라이언트와 서버 사이에 연결은 성공하였지만, 요청이 서버에 도착하지 않음을 의미
    * 429 Too Many Requests: 클라이언트가 서버에 너무 많은 요청을 보낸 경우
* <b>500번 대</b> 
클라이언트가 아닌 서버에서 에러가 발생하는 경우
    * 500 Internal Server Error: 백엔드에서 알 수 없는 에러가 발생했다는 의미
    * 502 Bad Gateway: 백엔드가 죽은 상태. 백엔드 앞에 프록시 서버를 두고 프록시와 백엔드 간 연결된 추상적인 통로를 <b>Gateway</b>라고 부른다.
    * 503 Service Unavailable: 서버가 요청을 처리할 준비가 되어있지 않음을 의미
    * 504 Gateway Timeout: 408 코드 에러와 마찬가지로 요청에 대한 타임 아웃을 의미. 그러나 요청에 대한 타임 아웃이 아닌 백엔드 아키텍처 내부에서 서버끼리 주고 받는 요청에서 발생

#### Try/catch문으로 예외 처리
```
try{
    //에러가 발생할 수 있는 코드
    throw new Exception(); //강제 에러 출력 
}catch (Exception e){
    //에러시 수행
     e.printStackTrace(); //오류 출력(방법은 여러가지)
     throw e; //최상위 클래스가 아니라면 무조건 던질 것
}finally{
    //무조건 수행
} 
```
try 블록에서 예외가 발생하면 즉시 실행을 멈추고 catch 블록으로 이동하여 예외 처리 코드를 실행한다. 그리고 마지막으로 finally 블록 코드를 실행한다.   

try/catch문을 주로 사용하는 때는 데이터 베이스에서 데이터를 주고 받거나 네트워크 처리를 할 때 사용한다. 이 처럼 변수가 많이 생기는 경우에 꼭 사용해야 하는 구문이다. 그리고 주로 마지막 finally에서는 연결을 끊는 상태 코드를 작성한다.   

<b>예외는 반드시 Throw를 해주어야 한다.</b>   
최상단 클래스를 제외한 나머지 클래스에서 예외 처리는 반드시 Throw를 해주어야 한다. 그렇지 않으면 예외 처리를 했음에도 불구하고 Main에서 Exception을 전달받지 못하여 개발자가 예외를 인지하지 못하는 경우가 생긴다.

### ◆ 네트워크 라이브러리
#### 소켓(Socket) 라이브러리
프로그램이 네트워크에서 데이터를 송수신할 수 있도록 ```네트워크 환경에 연결할 수 있도록 만들어진 연결부```를 네트워크 소켓이라고 한다.   

정확히 <b>네트워크 소켓</b>라는 단어는 정확한 표현이 아니다. 네트워크에 연결하기 위한 소켓 혹은 정해진 규약. 즉, 통신을 위한 프로토콜에 맞게 만들어져야 한다. 보통 OSI 7 Layer의 네 번째 계층, TCP 상에서 동작하는 소켓을 주로 사용하며 이를 <B>TCP 소켓</B> 혹은 <B>TCT/IP 소켓</B>이라고 부른다.   

#### TCP/IP 소켓 프로그래밍
소켓 프로그래밍은 소켓으로 네트워크 통신 기능을 구현하기 위해 소켓을 만드는 것과 만들어진 소켓을 통해 데이터를 주고 받는 절차를 제대로 이해해야 하며, 운영체제 및 프로그래밍 언어에 종속적으로 제공되는 소켓 API 사용법을 숙지해야 한다.   

그리고 케이블 분리로 인한 네트워크 단절, 트래픽 증가에 따른 데이터 전송 지연, 시스템 리소스 관리 문제로 인한 에러 등 네트워크 환경에서 발생할 수 있는 다양한 예외 사항에 대해 처리가 필요하여 어려울 수 있다.   

#### 클라이언트 소켓과 서버 소켓
두 시스템 간에 소켓을 통해 네트워크 연결을 하기 위해서는 최초 어느 한 곳에서 그 대상이 되는 곳을 연결해야 한다. IP주소와 포트 번호로 식별되는 대상에 자신이 데이터 송수신을 위한 네트워크 연결을 수립할 의사를 전달해야 하는 것이다.   

그렇지만 연결을 시도하고 요청을 보낸다고 해서 무조건 받아지는 것은 아니다. 그 대상이 준비가 되어있지 않는다면 연결은 이어지지 않는다. 그러므로 대상이 어떤 연결 요청(포트 번호 식별)을 받아들일 것인지 미리 시스템에 등록하여 요청이 들어왔을 때 처리할 수 있도록 준비해야 한다.   

두 개의 시스템이 소켓을 통해 데이터 통신을 위한 연결을 만들기 위해서는 요청을 보내는 클라이언트 소켓, 요청을 받는 서버 소켓이 있다.   

두 소켓은 이름은 다르지만 동일하며 역할과 구현 절차를 구분하게 위해 다르게 부른다. 서버 소켓은 클라이언트 소켓의 연결 요청을 받아들이는 역할만 수행할 뿐, 직접적인 데이터 송수신은 서버 소켓의 연결 요청 수락의 결과로 만들어지는 새로운 소켓을 통해 처리된다.

#### 소켓 API의 흐름
1. 클라이언트 소켓은 처음 소켓을 생성
2. 서버 측에 연결을 요청
3. 서버 소켓에서 연결이 받아지면 송수신
4. 모든 처리가 완료되면 소켓 닫기

#### 클라이언트 소켓 프로그래밍
소켓 API의 실행 흐름은 직관적이라 클라이언트 소켓을 다루는 과정은 이해하기 어렵다.   

* 클라이언트 소켓 생성 ( Socket() )   
가장 먼저해야 할 일로 생성할 때, 소켓 종류를 지정할 수 있다.
  * TCP 소켓을 위한 스트림 타입
  * UDP 소켓을 위한 데이터그램 타입   

최초 소켓이 생성되는 시점에는 어떠한 ```연결 대상```에 대한 정보가 들어 있지 않다. 연결 대상을 지정하고 연결 요청을 전달하기 위해 여기서 생성한 소켓을 사용해 Connect API를 호출해야 한다.   

* 연결 요청 ( Connect() )   
Connect API는 IP 주소와 포트 번호로 식별되는 대상으로 연결 요청을 보낸다.   

Connect API는 블럭(Block) 방식으로 동작하며 연결 요청에 대한 결과가 결정 되기 전에는 실행이 끝나지 않는다. 그러므로 API가 실행되자마자 결과와 상관 없이 무조건 Return될 것이라고 생각하면 안 된다.   

Connect API가 호출 성공이 되면 Send(), Recv API를 통해 데이터를 주고 받을 수 있다.   

* 데이터 송수신( Send(), Recv() )   
데이터를 보낼 때는 Send(), 받을 때는 Recv() API를 사용한다. 단순해보이지만 둘 다 블럭(Block) 방식을 사용한다. 모두 실행 결과(성공, 실패, 종료)가 결정되기 전에는 API가 Return되지 않는다. 에러가 발생하기 전까지 실행이 종료되지 않는다. 특히 Recv()는 데이터가 수신되거나 에러가 발생하기 전까지 실행이 종료되지 않기 때문에 데이터 수신 작업을 생각만큼 단순하게 처리하기 쉽지 않다.   

Send()의 경우 데이터를 보내는 주체가 자신이기 때문에 언제 어느 정도의 데이터를 보낼 지 알 수 있다. 하지만 데이터를 수신하는 경우, 통신 대상이 언제 어떤 데이터를 보낼 지 특정할 수 없기 때문에 Recv()가 실행 되면 언제 끝날 지 알 수 없다. 그래서 수신을 위한 Recv()는 별도의 스레드에서 실행한다.   

* 소켓 닫기 ( Close() )   
더 이상 데이터 송수신이 필요 없게 되면, 소켓을 닫기 위해 Close() API를 호출한다. Close()에 의해 닫힌 소켓은 더 이상 유효한 소켓이 아니기 때문에, 해당 소켓을 사용하여 데이터를 송수신할 수 없다.   

그리고 만약 소켓 연결이 종료된 후 또 다시 데이터를 주고 받고자 한다면, 또 한번의 소켓 생성과 연결 과정을 통해 소켓이 데이터를 송수신할 수 있는 상태가 되어야 한다.   

#### 서버 소켓 프로그래밍
소켓(Socket)에 IP 주소와 포트 번호를 결합하는 bind() API와 클라이언트 요청이 있는지 확인하는 listen() API의 존재한다.   

* 서버 소켓 생성. ( Socket() )   
서버 소켓을 사용하려면 최초 소켓을 생성해야 한다.   

* 서버 소켓 바인딩. ( Bind() )   
Bind() API에 사용되는 인자는 소켓(Socket)과 포트 번호(또는 IP 주소 + 포트 번호)다.   

운영체제에서는 소켓들이 중복된 포트 번호를 사용하지 않도록, 내부적으로 포트 번호와 소켓 연결 정보를 관리한다. 그리고 Bind() API는 해당 소켓이 지정된 포트 번호를 사용할 것이라는 것을 운영체제에 요청하는 API이다. 만약 지정된 포트 번호를 다른 소켓이 사용하고 있다면, Bind() API는 에러를 Return한다.   

정리하자면, 일반적으로 서버 소켓은 고정된 포트 번호를 사용한다. 그리고 그 포트 번호로 클라이언트의 연결 요청을 받아들이고 운영체제가 특정 포트 번호를 서버 소켓이 사용하도록 만들기 위해 소켓과 포트 번호를 결합(Bind)해야 하는데, 이 때 사용하는 API가 바로 Bind이다.   

* 클라이언트 연결 요청 대기. ( Listen() )   
클라이언트에 의한 연결 요청이 수신될 때까지 기다리는 역할을 담당한다.   

서버 소켓(Server Socket)에 바인딩된 포트 번호로 클라이언트의 연결 요청이 있는지 확인하며 대기 상태에 머문다.   

대기 상태에서 빠져나오는 경우   
1. 클라이언트 요청이 수신되는 경우   
2. 에러가 발생(소켓 Close() 포함)하는 경우   

Close() API가 성공한 경우라도 Return 값에 클라이언트의 요청에 대한 정보는 들어 있지 않다. 대신 클라이언트 연결 요청에 대한 정보는 시스템 내부적으로 관리되는 큐(Queue)에서 쌓이며 이 시점에서 클라이언트와의 연결은 아직 완전히 연결되지 않은 대기 상태이다.   

대기 중인 연결 요청을 큐(Queue)로부터 꺼내와서, 연결을 완료하기 위해서는 Accept() API를 호출해야 한다.   

* 클라이언트 연결 수립. ( Accept() )   
최종적으로 연결 요청을 받아들이는 역할을 수행한다. 그리고 사전적 의미만큼 직관적인 역할을 수행한다.   

최종적으로 연결된 소켓은 Bind(), Listen() API에서 사용한 소켓이 아닌 Accept() 내부에서 새로 만들어진 소켓이다.   

실질적인 데이터 송수신은 Accept() API에서 생성된, 연결이 수립된 소켓(Socket)을 통해 처리된다.   

* 데이터 송수신 ( Send() / Recv() )   
클라이언트 소켓 과정에서 설명한 것과 같다.   

* 소켓 연결 종료. ( Close() )   
클라이언트 소켓 처리 과정과 마찬가지로 소켓을 닫기 위해서는 Close() API를 호출한다.

그런데 서버 소켓에서는 Close()의 대상이 하나만 있는 것이 아니라는 것에 주의해야 한다. 최초 Socket() API를 통해 생성한 서버 소켓에 더해, Accept() API 호출에 의해 생성된 소켓도 관리해야 한다.   

---

### ◆ axios의 공통적인 에러처리 방법
프론트엔드에서 Axios 에러 처리는 ```API Server와 통신```할 때 자주 해야 한다.   

Axios의 에러 처리는 error.response를 사용해서 처리할 수 있다. 예를 들어
```
axios.get('/user/12345')
  .catch(function (error) {
    if (error.response) {
      // 요청이 이루어졌으며 서버가 2xx의 범위를 벗어나는 상태 코드로 응답했습니다.
      console.log(error.response.data);
      console.log(error.response.status);
      console.log(error.response.headers);
    }
    else if (error.request) {
      // 요청이 이루어 졌으나 응답을 받지 못했습니다.
      // `error.request`는 브라우저의 XMLHttpRequest 인스턴스 또는
      // Node.js의 http.ClientRequest 인스턴스입니다.
      console.log(error.request);
    }
    else {
      // 오류를 발생시킨 요청을 설정하는 중에 문제가 발생했습니다.
      console.log('Error', error.message);
    }
    console.log(error.config);
  });
```
위 처럼 error.response, error.request 등으로 오류를 처리하여 발생한 내용을 확인할 수 있다.   

* config 옵션에서 ```validateStatus```을 사용하여 사용자 정의 HTTP 상태 코드 오류 범위를 정의하기   
```
axios.get('/user/12345', {
  validateStatus: function (status) {
    // 상태 코드가 500 이상일 경우 거부. 나머지(500보다 작은)는 허용.
    return status < 500;
  }
})
```
   
Axios 에러 처리 중 특정 에러를 대응해주어야 할 때, ```코드 중복```이 자주 발생할 수 있다. 특히 ```401```과 같은 Token Expired은 공통적인 에러이다. 그렇다면 해당 에러를 하나로 묶어서 관리할 수 있도록 만들어야 한다.   

#### Axios Intercepter
Axios에는 Request 보내기 전 혹은 Response를 받기 전에 코드를 실행할 수 있다. 바로 ```Axios Intercepter```를 이용하면 된다. 예를 들어서 확인해보자.

```
const request = axios.create({
  timeout: 10000,
  baseURL: process.env.BASE_URL,
})
```
우선 axios.create로 axios 인스턴스를 생성한다. 그리고 Intercepter를 등록한다.

```
request.interceptors.response.use(
  response => {
    return response;
  },
  error => {
    if(error.response.status === '401') {
      -Error Handling Code-
    }
    return Promise.reject(error);
  },
);
```

위 처럼 Intercepter를 등록한다. response를 Intercepter하는 코드가 있는데 바로 interceptors.response.use이다. 이는 두 가지의 매개변수를 받는다.   

1. 첫 번째는 response를 가져오는 함수를 넣는다.   
2. 두 번째는 실패했을 때, error response를 가져오는 함수를 넣는다.   

Error Handling을 할 때, 두 번째 매개변수 함수에서 작업을 진행하면 된다.

---

### ◆ 페이지 접속 혹은 자바스크립트의 속도가 느릴 때 확인하는 방법
이전까지 성능에 대해 생각해본 적이 없었으나 모바일 접속의 증가로 자바스크립트 코드 작성에 따라 성능 차이를 보이기 시작했다. 현재 접속하고 있는 웹 페이지 혹은 자바스크립트 사용의 성능을 확인해보자.   

* 인터넷 접속 상태 확인하기   
* 크롬 개발자 도구에서 확인하기

#### 크롬 개발자 도구로 확인하기
1. 크롬 실행 - 보기 - 개발자 정보 - 개발자 도구
2. 개발자 도구에서 Profiles 탭 선택 - Start 버튼으로 성능 측정
3. 확인하고자 하는 웹 페이지 실행 후 결과 확인

#### 성능 측정하기

* Performance.now()   
DOMHighResTimeStamp에 접근할 수 있도록 해주며, 페이지를 로드한 이후로 지난 ms를 나타낸다. (최대 정밀도는 약 5µs)   

```
const t0 = performance.now()

for (let i = 0; i < array.length; i++) {
  // some code.......
}

const t1 = performance.now()

console.log(t1 - t0, 'ms')
```
위 코드를 보면 코드의 시작 시간을 t0에 저장하고 코드의 마지막 시간을 t1에 저장하였다. 그리고 마지막 시간에서 시작 시간을 빼면 코드 실행 시간을 알 수 있다.   

* Date.now를 써도 되는가?   
가능하다. 그러나 시스템의 시간에서 Unix Epoch(1970-01-01T00:00:00Z)의 차이를 Return한다. 이는 부정확하며 항상 증가한다고 할 수 없다.   

#### Performance.mark & Performance.measure
* Performance.mark   
코드 내에서 마킹을 할 수 있다. 마크는 Performance Buffer에서 Timestamp를 생성하여 나중에 코드의 특정 부분을 실행하는데 거린 시간을 측정하는데 사용할 수 있다.   

마킹을 생성하기 위해서 String을 파라미터로 함수를 호출해야 하며, 이 String은 나중에 식별자 용도로 사용된다. (최대 정밀도는 약 5µs)   

```
performance.mark('name')
```

```
* detail: null
* name: "name"
* entryType: "mark"
* startTime: 268528.33999999985
* duration: 0
```

* Performance.measure   
이 함수는 1~3개의 Arguments를 받는다. 첫 번째 인수는 <b>name</b>이고, 나머치는 측정하고 싶은 영역이다.   

1. 네비케이션 측정 시작
```
performance.measure('measure name')
```

2. 네비게이션 시작부터 특정 마킹까지 확인
```
performance.measure('measure name', undefined, 'mark-2')
```

3. 특정 마킹부터 바킹까지 확인
```
performance.measure('measure name', 'mark-1', 'mark-2')
```

4. 마킹부터 지금까지 확인
```
performance.measure('measure name', 'mark-1')
```

#### 측정 값 수집하기
<b>Performance Entry Buffer</b>로부터 데이터 수집하기   

이를 위해 Performance API는 3종류의 API를 제공한다.   

* performance.getEntries(): performance entry buffer에 저장된 모든 것.
* performance.getEntriesByName('name')   
* performance.getEntriesByType('type'): 특정 타입에 대해서만. measure, mark만 가능   

모든 예제 종합.
```
performance.mark('mark-1')

// 성능을 측정할 코드...........

performance.mark('mark-2')

performance.measure('test', 'mark-1', 'mark-2')

console.log(performance.getEntriesByName('test')[0].duration)
```

<b>Console.time</b>으로 측정하기   
단순히 console.time을 호출하고, 측정 종류 시점에 console.timeEnd를 호출하면 된다.

```
console.time('test')

for (let i = 0; i < array.length; i++) {
  // some code
}

console.timeEnd('test')
```

#### 측정 시 주의해야 할 것
1. <b>분할해서 살펴볼 것</b>   
단순히 코드의 어느 부분이 느린지 추측하기 보다 위 기능들을 사용하여 각각 나눠서 측정하는 것이 좋다.   

느린 부분을 찾기 위해, 느린 코드 블록 위주로 console.time을 배치하는 것이 좋다. 그 다음 각 부분의 성능을 측정하는 것이 좋다.   

2. <b>입력 값에 주의를 기울일 것</b>   
실제 웹 페이지 혹은 애플리케이션은 함수의 입력 값에 따라 결과가 달라질 수 있다. 랜덤 값으로 테스트하는 것이 아니라 실제 사용되는 예제를 바탕으로 측정하는 것이 좋다.   

3. <b>함수를 여러 번 실행할 것</b>   
배열을 순회하는 함수 내에서 각각의 원소값을 계산하고 그 결과를 배열로 반환하는 함수가 있을 때, forEach, for문 중에서 성능에서 우위가 있나 고민해볼 때, 사실상 별반 차이가 없다. 다만 둘 중 하나를 선택하자면 for문을 선택하는 것이 나을 수 있다.   

#### CPU 스로틀링 확인하기
항상 내가 개발하고 있는 컴퓨터는 대부분의 사용자가 사용하는 모바일 환경보다 더 빠르다는 것을 염두해 두어야 한다. 브라우저별로 CPU 성능을 쓰로틀 해주는 기능을 가지고 있으므로, 이를 활용해서 테스트 해야 한다.
